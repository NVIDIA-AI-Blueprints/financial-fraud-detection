{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The objective of this notebook is to showcase the usage of the [___financial-fraud-training___ container](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/cugraph/containers/financial-fraud-training) and how to deploy the produced trained models on [NVIDIA Dynamo-Triton](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver).\n",
    "- We use [IBM TabFormer](https://github.com/IBM/TabFormer) as an example dataset and the dataset is preprocess before model training\n",
    "\n",
    "NOTE:\n",
    "* The preprocessing code is written specifically for the TabFormer dataset and will not work with other datasets.\n",
    "* Additionally, a familiarity with [Jupyter](https://docs.jupyter.org/en/latest/what_is_jupyter.html) is assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup (Local and Brev)\n",
    "This Notebook is designed to work in both a ___Local___ and ___Brev___ environment.  However, there are a few slight differences that will be pointed out. \n",
    "\n",
    "### For Local Environment Setup\n",
    "Please create a Conda environment and add that to the notebook - See the [README](../README.md) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default host for local run\n",
    "HOST = \"0.0.0.0\"\n",
    "BREV = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Brev Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r \"./requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BREV = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brev public IP address\n",
    "if BREV:\n",
    "    HOST = 'host.docker.internal'\n",
    "HOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Import libraries (both environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Step 1: Get and Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Local\n",
    "1. Download the dataset: https://ibm.ent.box.com/v/tabformer-data/folder/130747715605\n",
    "2. untar and uncompreess the file: `tar -xvzf ./transactions.tgz`\n",
    "3. Put card_transaction.v1.csv in in the `data/TabFormer/raw` folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Brev \n",
    "1. Download the dataset: https://ibm.ent.box.com/v/tabformer-data/folder/130747715605\n",
    "2. In the Jupyter notebook window, use the \"File Browser\" section to the data/Tabformer/raw folder\n",
    "3. Drag-and-drop the \"transactions.tgz\" file into the folder\n",
    "    - There is also an \"upload\" option that displays a file selector\n",
    "    - Please wait for the upload to finish, it could take a while, by lookign at the status indocator at the bottom of the window\n",
    "4. Now uncompress and untar by running the following command\n",
    "    - Note: if somethign goes wrong you will need to delete the file rather than trying to overwrite it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that the compressed file was uploaded successfully - the size should be 266M\n",
    "!ls -lh ../data/TabFormer/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncompress/untar the file\n",
    "!tar xvzf ../data/TabFormer/raw/transactions.tgz -C ../data/TabFormer/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If__ drag-and-drop is not working, please run the [Download TabFormer](./extra/download-tabformer.ipynb) notebook is the \"extra\" folder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data folder structure\n",
    "The goal is to produce the following structure\n",
    "\n",
    "```\n",
    ".\n",
    "    data\n",
    "    └── TabFormer\n",
    "        └── raw\n",
    "            └── card_transaction.v1.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the raw data is placed as described above, set the path to the TabFormer directory\n",
    "\n",
    "# Change this path to point to TabFormer data\n",
    "data_root_dir = os.path.abspath('../data/TabFormer/') \n",
    "\n",
    "# Change this path to the directory where you want to save your model\n",
    "model_output_dir = os.path.join(data_root_dir, 'trained_models')\n",
    "\n",
    "# Path to save the trained model\n",
    "os.makedirs(model_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define python function to print directory tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(directory, prefix=\"\"):\n",
    "    \"\"\"Recursively prints the directory tree starting at 'directory'.\"\"\"\n",
    "    # Retrieve a sorted list of entries in the directory\n",
    "    entries = sorted(os.listdir(directory))\n",
    "    entries_count = len(entries)\n",
    "    \n",
    "    for index, entry in enumerate(entries):\n",
    "        path = os.path.join(directory, entry)\n",
    "        # Determine the branch connector\n",
    "        if index == entries_count - 1:\n",
    "            connector = \"└── \"\n",
    "            extension = \"    \"\n",
    "        else:\n",
    "            connector = \"├── \"\n",
    "            extension = \"│   \"\n",
    "        \n",
    "        print(prefix + connector + entry)\n",
    "        \n",
    "        # If the entry is a directory, recursively print its contents\n",
    "        if os.path.isdir(path):\n",
    "            print_tree(path, prefix + extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the raw data has been placed properly\n",
    "print_tree(data_root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: Preprocess the data \n",
    "- Import the Python function for preprocessing the TabFormer data\n",
    "- Call `preprocess_TabFormer` function to prepare the data\n",
    "\n",
    "NOTE: The preprocessing can takes a few minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the \"src\" directory to the search path\n",
    "src_dir = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "sys.path.insert(0, src_dir)\n",
    "\n",
    "# should be able to import from \"src\" folder now\n",
    "from preprocess_TabFormer import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "mask_mapping, feature_mask = preprocess_data(data_root_dir)\n",
    "\n",
    "# this will output status as it correlates different attributes with target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should not see files under a \"gnn\" folder and under a \"xgb\" folder\n",
    "print_tree(data_root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Step 3:  Now train the model using the financial-fraud-training container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training configuration file\n",
    "NOTE: Training configuration file must conform to schema defined [here](https://docs.nvidia.com/nim/financial-fraud-training/latest/configuration/config-json.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important: Models and configuration files needed for deployment using NVIDIA Dynamo-Triton will be saved in model-repository under the folder that is mounted in /trained_models inside the container__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "  \"paths\": {\n",
    "    \"data_dir\": \"/data\", # Mount dataset root directory under /data in the container\n",
    "    \"output_dir\": \"/trained_models\" # Mount path to save the trained models.\n",
    "                                    # NOTE: This path is inside the docker container \n",
    "  },\n",
    "\n",
    "  \"models\": [\n",
    "    {\n",
    "      \"kind\": \"GraphSAGE_XGBoost\",\n",
    "      \"gpu\": \"single\",\n",
    "      \"hyperparameters\": {\n",
    "        \"gnn\":{\n",
    "          \"hidden_channels\": 16,\n",
    "          \"n_hops\": 1,\n",
    "          \"dropout_prob\": 0.1,\n",
    "          \"batch_size\": 1024,\n",
    "          \"fan_out\": 16,\n",
    "          \"num_epochs\": 16\n",
    "        },\n",
    "        \"xgb\": {\n",
    "          \"max_depth\": 6,\n",
    "          \"learning_rate\": 0.2,\n",
    "          \"num_parallel_tree\": 3,\n",
    "          \"num_boost_round\": 512,\n",
    "          \"gamma\": 0.0\n",
    "        }\n",
    "\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the training configuration as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config_file_name = 'training_config.json'\n",
    "\n",
    "with open(os.path.join(training_config_file_name), 'w') as json_file:\n",
    "    json.dump(training_config, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull and run the financial_fraud_training container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Logging into the NVIDIA Container Registry.\n",
    "\n",
    "The NVIDIA NGC API Key is a mandatory key that is required to use this blueprint. This is needed to log into the NVIDIA container registry, nvcr.io, and to pull secure container images used in this NVIDIA NIM Blueprint. Refer to [Generating NGC API Keys](https://docs.nvidia.com/ngc/gpu-cloud/ngc-user-guide/index.html#generating-api-key) in the NVIDIA NGC User Guide for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=\"PASTE YOUR NGC API KEY HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authenticate with the NVIDIA Container Registry with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"$API_KEY\" | docker login nvcr.io --username '$oauthtoken' --password-stdin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull the container image from the NGC registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull nvcr.io/nvidia/cugraph/financial-fraud-training:1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set container name and ports for running the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIM_HTTP_PORT = 8002\n",
    "NIM_GRPC_PORT = 50051\n",
    "CONTAINER_NAME = \"financial-fraud-training\"\n",
    "gnn_data_dir = os.path.join(data_root_dir, \"gnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop any running container with the same name\n",
    "container_ids = !docker ps --filter \"name={CONTAINER_NAME}\" -q\n",
    "if len(container_ids) > 0:\n",
    "    !docker stop {CONTAINER_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BREV:\n",
    "    host_path_gnn_data = gnn_data_dir.replace('/root/verb-workspace', '/home/ubuntu/workspace')\n",
    "    host_path_trained_models = model_output_dir.replace('/root/verb-workspace', '/home/ubuntu/workspace')\n",
    "else:\n",
    "    host_path_gnn_data = gnn_data_dir\n",
    "    host_path_trained_models = model_output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -d -it --rm --name={CONTAINER_NAME} --gpus \"device=0\" \\\n",
    "    -p {NIM_HTTP_PORT}:{NIM_HTTP_PORT} -e NIM_HTTP_API_PORT={NIM_HTTP_PORT} -p {NIM_GRPC_PORT}:{NIM_GRPC_PORT} \\\n",
    "    -e NIM_DISABLE_MODEL_DOWNLOAD=True -e NIM_GRPC_API_PORT={NIM_GRPC_PORT} -v {host_path_gnn_data}:/data \\\n",
    "    -v {host_path_trained_models}:/trained_models nvcr.io/nvidia/cugraph/financial-fraud-training:1.0.1 -e NGC_API_KEY={API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, initiate model training using the training configuration defined earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate training via the /train endpoint by sending the training configuration as a JSON payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \"http://{HOST}:$NIM_HTTP_PORT/train\"   -H \"Content-Type: application/json\"   -d @{training_config_file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_ids = !docker ps --filter \"name={CONTAINER_NAME}\" -q\n",
    "if len(container_ids) > 0:\n",
    "    !docker stop {CONTAINER_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure that `python_backend_model_repository` has been created with right contents\n",
    "According to the training configuration file defined earlier, if the trining run successfully, a folder titled `python_backend_model_repository` containing a python backend model and a configuration file will be created under \n",
    "{model_output_dir} and its contents should look like\n",
    "\n",
    "```sh\n",
    "python_backend_model_repository/\n",
    "└── prediction_and_shapley\n",
    "    ├── 1\n",
    "    │   ├── embedding_based_xgboost.json\n",
    "    │   ├── model.py\n",
    "    │   └── state_dict_gnn_model.pth\n",
    "    └── config.pbtxt\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(os.path.join(model_output_dir, 'model_repository'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Step 4:  Serve your python backend model using NVIDIA Dynamo-Triton\n",
    "__!Important__: Change MODEL_REPO_PATH to point to `{model_output_dir}` / `python_backend_model_repository` if you used a different path in your training configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install NVIDIA Dynamo-Triton Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'tritonclient[all]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as triton_grpc\n",
    "import tritonclient.http as httpclient\n",
    "from tritonclient import utils as triton_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace HOST with the actual URL where your NVIDIA Dynamo-Triton server is hosted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTTP_PORT = 8005\n",
    "GRPC_PORT = 8006\n",
    "METRICS_PORT = 8007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serve your models with NVIDIA Dynamo-Triton\n",
    "- Pull the NVIDIA Dynamo-Triton docker image\n",
    "- Deploy server with models and configuration files (produced by the training container)\n",
    "- Double check that your `python_backend_model_repository` folder, located under `${model_output_dir}`, has the following structures\n",
    "```sh\n",
    "python_backend_model_repository/\n",
    "└── prediction_and_shapley\n",
    "    ├── 1\n",
    "    │   ├── embedding_based_xgboost.json\n",
    "    │   ├── model.py\n",
    "    │   └── state_dict_gnn_model.pth\n",
    "    └── config.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA Dynamo-Triton image\n",
    "TRITON_IMAGE = 'nvcr.io/nvidia/tritonserver:25.04-py3'\n",
    "\n",
    "# Pull the Dynamo image\n",
    "!docker pull {TRITON_IMAGE}\n",
    "\n",
    "# Stop and remove any existing container\n",
    "container_ids = !docker ps --filter \"name=tritonserver\" -q\n",
    "if len(container_ids) > 0:\n",
    "    !docker stop tritonserver\n",
    "    !docker rm tritonserver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the container\n",
    "\n",
    "MODEL_REPO_PATH = os.path.join(model_output_dir, 'python_backend_model_repository')\n",
    "if BREV:\n",
    "    HOST_MODEL_REPO_PATH = MODEL_REPO_PATH.replace('/root/verb-workspace', '/home/ubuntu/workspace')\n",
    "else:\n",
    "    HOST_MODEL_REPO_PATH = MODEL_REPO_PATH\n",
    "\n",
    "!docker run --gpus \"device=0\" -d -p {HTTP_PORT}:{HTTP_PORT} -p {GRPC_PORT}:{GRPC_PORT} \\\n",
    "    -v {HOST_MODEL_REPO_PATH}:/models --name tritonserver {TRITON_IMAGE} tritonserver \\\n",
    "    --model-repository=/models --exit-timeout-secs=6000 --http-port={HTTP_PORT} --grpc-port={GRPC_PORT} \\\n",
    "    --metrics-port={METRICS_PORT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLs for GRPC and HTTP request to the inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_grpc = triton_grpc.InferenceServerClient(url=f'{HOST}:{GRPC_PORT}')\n",
    "client_http = httpclient.InferenceServerClient(url=f'{HOST}:{HTTP_PORT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for NVIDIA Dynamo-Triton to install packages and come online\n",
    "**NOTE**: This cell can take a few minutes to execute.\n",
    " If the following cell keeps running even after you see `Started HTTPService at {HOST}:{HTTP_PORT}` in the log, you can interrupt the execution of this cell and continue from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "container_name = \"tritonserver\"\n",
    "\n",
    "while True:\n",
    "    client_grpc = triton_grpc.InferenceServerClient(url=f'{HOST}:{GRPC_PORT}')\n",
    "    try:\n",
    "        if client_grpc.is_server_ready():\n",
    "            break\n",
    "    except triton_utils.InferenceServerException as e:\n",
    "        pass\n",
    "    try:\n",
    "        # Run the docker logs command with the --tail option\n",
    "        output = subprocess.check_output([\"docker\", \"logs\", \"--tail\", \"10\", container_name])\n",
    "        print(output.decode(\"utf-8\"))\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error retrieving logs:\", e)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if NVIDIA Dynamo-Triton is running properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker logs tritonserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction without computing Shapley values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read preprocessed input transactions to send query to NVIDIA Dynamo-Triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"prediction_and_shapley\"\n",
    "test_X_path = os.path.join(gnn_data_dir, \"test_gnn\", \"nodes/node.csv\") # already preprocessed data\n",
    "test_X = pd.read_csv(test_X_path)\n",
    "X = test_X.values.astype(np.float32)\n",
    "\n",
    "test_y_path = os.path.join(gnn_data_dir, \"test_gnn\", \"nodes/node_label.csv\") # already preprocessed data\n",
    "test_y = pd.read_csv(test_y_path)\n",
    "y = test_y.values.astype(np.float32)\n",
    "\n",
    "test_ei_path = os.path.join(gnn_data_dir, \"test_gnn\", \"edges/node_to_node.csv\") \n",
    "test_ei = pd.read_csv(test_ei_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = test_ei.values.T.astype(np.int64)\n",
    "compute_shap = np.array([False], dtype=bool) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance for a batch of transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision threshold to flag a transaction as fraud\n",
    "#Change to trade-off precision and recall\n",
    "decision_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_score_for_batch(edge_idx, X, y, batch_size, decision_threshold = 0.5, shap=False, feature_mask=None):\n",
    "    edge_index = edge_idx.T.astype(np.int64)\n",
    "    compute_shap = np.array([shap], dtype=bool) # Skip Shapley value computation\n",
    "    \n",
    "    with httpclient.InferenceServerClient(f\"{HOST}:{HTTP_PORT}\") as client:\n",
    "        input_features = httpclient.InferInput(\"NODE_FEATURES\", X.shape, datatype=\"FP32\")\n",
    "        input_features.set_data_from_numpy(X)\n",
    "\n",
    "        input_edge_indices = httpclient.InferInput(\"EDGE_INDEX\", edge_index.shape, datatype=\"INT64\")\n",
    "        input_edge_indices.set_data_from_numpy(edge_index)\n",
    "\n",
    "        # Even though Shapley values are not requested, it still requires a feature mask.\n",
    "        # It can be a dummy array of int values, but the length must be same as number of features.\n",
    "\n",
    "        if shap:\n",
    "            assert X.shape[1] == len(feature_mask)\n",
    "            feature_mask = np.array(feature_mask).astype(np.int32)\n",
    "        else:\n",
    "            feature_mask = np.zeros(X.shape[1]).astype(np.int32)\n",
    "\n",
    "        input_feature_mask = httpclient.InferInput(\"FEATURE_MASK\", feature_mask.shape, datatype=\"INT32\")\n",
    "        input_feature_mask.set_data_from_numpy(feature_mask)\n",
    "\n",
    "        compute_shap_flag = httpclient.InferInput(\"COMPUTE_SHAP\", compute_shap.shape, datatype=\"BOOL\")\n",
    "        compute_shap_flag.set_data_from_numpy(compute_shap)\n",
    "        \n",
    "        outputs = [\n",
    "            httpclient.InferRequestedOutput(\"PREDICTION\"),\n",
    "            httpclient.InferRequestedOutput(\"SHAP_VALUES\")\n",
    "        ]\n",
    "\n",
    "        # Send query to the server\n",
    "        response = client.infer(\n",
    "            model_name,\n",
    "            inputs=[input_features, input_edge_indices, compute_shap_flag, input_feature_mask],\n",
    "            request_id=str(1),\n",
    "            outputs=outputs,\n",
    "            timeout= 3000\n",
    "            )\n",
    "        \n",
    "    predictions = response.as_numpy('PREDICTION')\n",
    "\n",
    "    assert y.sum() == y[-batch_size:].sum()\n",
    "    if shap == False:\n",
    "        y_pred = (predictions > decision_threshold).astype(int)\n",
    "        \n",
    "        # Compute evaluation metrics\n",
    "        accuracy = accuracy_score(y[-batch_size:], y_pred[-batch_size:])\n",
    "        precision = precision_score(y[-batch_size:], y_pred[-batch_size:], zero_division=0)\n",
    "        recall = recall_score(y[-batch_size:], y_pred[-batch_size:], zero_division=0)\n",
    "        f1 = f1_score(y[-batch_size:], y_pred[-batch_size:], zero_division=0)\n",
    "\n",
    "\n",
    "\n",
    "        classes = ['Non-Fraud', 'Fraud']\n",
    "        columns = pd.MultiIndex.from_product([[\"Predicted\"], classes])\n",
    "        index = pd.MultiIndex.from_product([[\"Actual\"], classes])\n",
    "\n",
    "        conf_mat = confusion_matrix(y[-batch_size:], y_pred[-batch_size:])\n",
    "        cm_df = pd.DataFrame(conf_mat, index=index, columns=columns)\n",
    "        print(cm_df)\n",
    "\n",
    "        # Plot the confusion matrix directly from predictions\n",
    "        disp = ConfusionMatrixDisplay.from_predictions(\n",
    "            y[-batch_size:], y_pred[-batch_size:], display_labels=classes)\n",
    "        disp.ax_.set_title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"----Summary---\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return predictions, response.as_numpy('SHAP_VALUES') if shap else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample a batch of transactions from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# In the preprocessing code, zero-based user node indices come first, \n",
    "# followed by merchant node indices, and then transaction node indices.\n",
    "\n",
    "# Each transaction is represented by four edges,\n",
    "    # user to transaction,\n",
    "    # transaction to merchant,\n",
    "    # transaction to user\n",
    "    # merchant to transaction\n",
    "\n",
    "# Each transaction involves three nodes - an user, a transaction and a merchant\n",
    "\n",
    "\n",
    "NR_TX =  test_ei.shape[0]//4\n",
    "batch_size = NR_TX\n",
    "\n",
    "transaction_batch = np.random.choice(NR_TX, size=batch_size, replace=False)\n",
    "idx_of_edges = transaction_batch.reshape(-1, 1) + np.arange(4)*NR_TX\n",
    "edges_batch = test_ei.iloc[idx_of_edges.ravel()]\n",
    "unique_vertices, renumbered_edges =  np.unique(edges_batch.values, return_inverse=True)\n",
    "eidx = renumbered_edges.reshape(edges_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y[unique_vertices][-batch_size:].sum() == y[unique_vertices].sum()\n",
    "y[unique_vertices][-batch_size:].sum(), y[unique_vertices].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, _ = compute_score_for_batch(eidx, X[unique_vertices], y[unique_vertices], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Shapley values of different features for a transaction\n",
    "NOTE: Shapely computation is very expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_TX =  test_ei.shape[0]//4\n",
    "batch_size = 1 \n",
    "\n",
    "transaction_batch = np.random.choice(NR_TX, size=batch_size, replace=False)\n",
    "idx_of_edges = transaction_batch.reshape(-1, 1) + np.arange(4)*NR_TX\n",
    "\n",
    "edges_batch = test_ei.iloc[idx_of_edges.ravel()]\n",
    "unique_vertices, renumbered_edges =  np.unique(edges_batch.values, return_inverse=True)\n",
    "\n",
    "\n",
    "predictions, shap_values = compute_score_for_batch(renumbered_edges.reshape(edges_batch.shape), X[unique_vertices], y[unique_vertices], batch_size=batch_size, shap=True, feature_mask=feature_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_attribution_map = dict(zip(feature_mask, shap_values[2]))\n",
    "feature_name_to_id_map = {v:k for k, v in mask_mapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapley values for different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{feature_name_to_id_map[k]: f\"{v:.3f}\" for k, v in feature_to_attribution_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_env_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
